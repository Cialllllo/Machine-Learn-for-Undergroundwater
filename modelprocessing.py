from sklearn.ensemble import RandomForestRegressor
from sklearn.ensemble import GradientBoostingRegressor
import lightgbm as GBM
from sklearn.multioutput import MultiOutputRegressor
import xgboost as xgb
import json
import joblib
import pandas as pd
from sklearn.model_selection import train_test_split,cross_val_score,KFold
from sklearn.metrics import r2_score
from sklearn.preprocessing import StandardScaler
import numpy as np
import matplotlib.pyplot as plt
from scipy.stats import ttest_rel
import shap
import gc
import warnings
warnings.filterwarnings("ignore")


# åœ¨ modelprocessing.py ä¸­æ·»åŠ ä»¥ä¸‹å‡½æ•°

from sklearn.metrics import mean_squared_error, mean_absolute_error

def calculate_metrics(y_true, y_pred):
    """
    è®¡ç®—å¹¶è¿”å›å¸¸è§å›å½’æŒ‡æ ‡

    å‚æ•°:
        y_true (np.ndarray): çœŸå®å€¼
        y_pred (np.ndarray): é¢„æµ‹å€¼

    è¿”å›:
        dict: åŒ…å«å„ç§æŒ‡æ ‡çš„å­—å…¸
    """
    mse = mean_squared_error(y_true, y_pred)
    rmse = np.sqrt(mse)
    mae = mean_absolute_error(y_true, y_pred)
    r2 = r2_score(y_true, y_pred)

    return {
        'MSE': float(mse),
        'RMSE': float(rmse),
        'MAE': float(mae),
        'R2': float(r2)
    }

class Encoder(json.JSONEncoder):
    def default(self, obj):
        if isinstance(obj, np.integer):
            return int(obj)
        elif isinstance(obj, np.floating):
            return float(obj)
        elif isinstance(obj, np.ndarray):
            return obj.tolist()
def data_processing(relation = 'GW_RCHG',func = 'cubic',scale = True,back = False):
    # è¯»å–å‡†å¤‡å¥½çš„ç‰¹å¾
    features = pd.read_csv(r'features.csv')
    data_label = pd.read_csv(fr'.\label\{relation}_{func}_relation.csv')  # è¿™é‡Œéœ€è¦æ”¹æˆå®é™…çš„æ ‡ç­¾æ–‡ä»¶å

    # æ­£ç¡®åšæ³•ï¼šå…ˆåˆ’åˆ†ï¼Œå†åˆ†åˆ«æ ‡å‡†åŒ–
    X_train, X_test, y_train, y_test = train_test_split(features, data_label, test_size=0.3, random_state=30)

    # å¯¹æ ‡ç­¾æ ‡å‡†åŒ–
    if scale:

        y_standard = StandardScaler()
        y_train_scaled = y_standard.fit_transform(y_train)  # åªç”¨è®­ç»ƒé›†æ‹Ÿåˆ
        y_test_scaled = y_standard.transform(y_test)  # ç”¨è®­ç»ƒé›†çš„å‚æ•°è½¬æ¢æµ‹è¯•é›†
        if back:
            # è¿™ä¸ªå†³å®šä½ æ˜¯å¦è¿”å›æ ‡å‡†ç¼©æ”¾
            return X_train,X_test,y_train_scaled,y_test_scaled,y_standard
        else:
            return X_train,X_test,y_train_scaled,y_test_scaled
    else:
        if back:
            assert not back,'ä½ æ˜æ˜ä¸è¦æ ‡å‡†åŒ–çš„ï¼Œä½ è¦backå¹²å•¥'
            return X_train, X_test, y_train, y_test
        else:
            return X_train, X_test, y_train, y_test



def rf_processing(relation = 'GW_RCHG',func = 'cubic'):
    with open(f'./RF_params/{relation}_{func}_params.json', 'r', encoding='utf-8') as file:
        # ä½¿ç”¨ json.load() æ–¹æ³•åŠ è½½æ–‡ä»¶å†…å®¹å¹¶è½¬æ¢ä¸º Python å¯¹è±¡
        params = json.load(file)
    # è¿”å›æœ€ä½³å‚æ•°çš„æ¨¡å‹
    base_model = RandomForestRegressor()
    model = MultiOutputRegressor(base_model,n_jobs=1).set_params(**params)
    return model

def xgb_processing(relation = 'GW_RCHG',func = 'cubic'):
    params = joblib.load(f'./XGB_model/{relation}_{func}_relation_model.pkl').get_params()
    base_model = xgb.XGBRegressor()
    model = MultiOutputRegressor(base_model,n_jobs=1).set_params(**params)
    return model

def gbr_processing(relation = 'GW_RCHG',func = 'cubic'):
    with open(f'./GBR_params/{relation}_{func}_params.json', 'r', encoding='utf-8') as file:
        params = json.load(file)
    base_model = GradientBoostingRegressor()
    # ä¿®æ­£å‚æ•°ä¼ é€’
    model = MultiOutputRegressor(base_model,n_jobs=1)
    model.set_params(**params)  # æ­£ç¡®è®¾ç½®å‚æ•°çš„æ–¹å¼
    return model

def gbm_processing(relation = 'GW_RCHG',func = 'cubic'):
    with open(f'./LightGBM_params/{relation}_{func}_params.json', 'r', encoding='utf-8') as file:
        params = json.load(file)
    base_model = GBM.LGBMRegressor(verbose = -1)
    # ä¿®æ­£å‚æ•°ä¼ é€’
    model = MultiOutputRegressor(base_model,n_jobs=1)
    model.set_params(**params)  # æ­£ç¡®è®¾ç½®å‚æ•°çš„æ–¹å¼
    return model


def multioutput_rfecv(model_process,
                             relation='GW_RCHG',
                             func='cubic',
                             min_features_to_select=1,
                             step=1,
                             cv_splits=5):

    # æ•°æ®å‡†å¤‡
    X_train, X_test, y_train, y_test = data_processing(relation, func)

    # åˆå§‹åŒ–åŸºç¡€æ¨¡å‹ï¼ˆåªä¸ºäº†è·å–ç»“æ„ï¼Œä¸ç”¨äºè®­ç»ƒï¼‰
    base_model = model_process(relation, func)
    if hasattr(base_model, "n_jobs"):
        base_model.set_params(n_jobs=1)

    # å¼ºåˆ¶ base model çš„å­æ¨¡å‹å•çº¿ç¨‹
    for est in getattr(base_model, "estimators_", []):
        if hasattr(est, "n_jobs"):
            est.set_params(n_jobs=1)
        if hasattr(est, "nthread"):
            est.set_params(nthread=1)

    n_features = X_train.shape[1]
    current_features = np.arange(n_features)

    cv = KFold(n_splits=cv_splits, shuffle=True, random_state=30)

    # ğŸ”¥ å†å²è®°å½•
    feature_hist = []   # æ¯ä¸€è½®çš„ç‰¹å¾ç´¢å¼•
    score_hist = []     # æ¯ä¸€è½®çš„CVå¾—åˆ†

    # ==========================
    #       RFECV ä¸»å¾ªç¯
    # ==========================
    while len(current_features) >= min_features_to_select:

        X_sub = X_train.iloc[:, current_features]

        cv_scores = []

        # æ‰‹å†™ CVï¼ˆé¿å… Windows å¹¶è¡Œå‡ºé”™ï¼‰
        for train_idx, val_idx in cv.split(X_sub):
            X_tr, X_val = X_sub.iloc[train_idx], X_sub.iloc[val_idx]
            y_tr, y_val = y_train[train_idx], y_train[val_idx]

            # æ¯æŠ˜ä¸€ä¸ªæ–°æ¨¡å‹
            m = model_process(relation, func)

            # å¼ºåˆ¶å•çº¿ç¨‹
            if hasattr(m, "n_jobs"):
                m.set_params(n_jobs=1)
            for est in getattr(m, "estimators_", []):
                if hasattr(est, "n_jobs"):
                    est.set_params(n_jobs=1)
                if hasattr(est, "nthread"):
                    est.set_params(nthread=1)

            m.fit(X_tr, y_tr)
            pred = m.predict(X_val)

            # å¤šè¾“å‡ºç»Ÿä¸€ R2
            score = r2_score(y_val, pred, multioutput='uniform_average')
            cv_scores.append(score)


        mean_score = np.mean(cv_scores)

        # è®°å½•å†å²
        feature_hist.append(current_features.copy())
        score_hist.append(mean_score)

        print(f"ç‰¹å¾æ•° {len(current_features)} â†’ CV å¹³å‡ RÂ² = {mean_score:.4f}")

        # æ‹Ÿåˆä¸€æ¬¡ï¼Œç”¨äºç‰¹å¾é‡è¦æ€§
        base_model.fit(X_sub, y_train)

        # å¹³å‡æ¯ä¸ªè¾“å‡ºçš„é‡è¦æ€§
        importances = np.mean(
            [est.feature_importances_ for est in base_model.estimators_],
            axis=0
        )

        # åˆ é™¤ step ä¸ªæœ€ä¸é‡è¦ç‰¹å¾
        least_k = np.argsort(importances)[:step]

        print(f"åˆ é™¤ç‰¹å¾: {current_features[least_k]}\n")

        # æ›´æ–°ç‰¹å¾é›†åˆ
        current_features = np.delete(current_features, least_k)

        gc.collect()

    # ==========================
    #      æ‰¾åˆ°æœ€ä½³ index
    # ==========================
    best_idx = np.argmax(score_hist)
    best_score = score_hist[best_idx]
    best_features = feature_hist[best_idx]

    print("============== ç»“æœæ€»ç»“ ==============")
    print(f"æœ€ä½³ç‰¹å¾æ•°é‡: {len(best_features)}")
    print(f"æœ€ä½³å¹³å‡ CV RÂ²: {best_score:.6f}")
    print("=====================================")

    # ç»˜åˆ¶æ›²çº¿
    plt.figure(figsize=(8, 5))
    plt.plot([len(f) for f in feature_hist[::-1]], score_hist[::-1],
             marker='o', markersize=6, linewidth=2, color='#2E86AB')
    plt.xticks(range(1, 22))
    plt.xlabel("Number of Features", fontsize=12, fontweight='bold')
    plt.ylabel("Cross-Validation RÂ² Score", fontsize=12, fontweight='bold')
    plt.grid(True, alpha=0.3, linestyle='--')
    plt.title(f"Feature Selection Performance: {relation} {func}",
              fontsize=14, fontweight='bold', pad=20)

    # Add some styling
    plt.gca().spines['top'].set_visible(False)
    plt.gca().spines['right'].set_visible(False)
    plt.tight_layout()
    plt.savefig(f'{relation}_{func}_rfecv.png')

    return best_features, best_score, feature_hist, score_hist


# æ›¿æ¢æˆ–æ›´æ–° modelprocessing.py ä¸­çš„ R2_plot å‡½æ•°ä¸ºå¦‚ä¸‹ç‰ˆæœ¬ï¼š

def R2_plot(Y_true,
            Y_pred,
            path='parity_plot_dynamic_limits.png',
            title="Model Performance For Param A"):
    """
    ç»˜åˆ¶çœŸå®å€¼ vs. é¢„æµ‹å€¼çš„æ•£ç‚¹å›¾ï¼Œå¹¶æ·»åŠ  y=x åŸºå‡†çº¿ã€‚
    è½´çš„èŒƒå›´ç”±æ•°æ®çš„æœ€å°å€¼å’Œæœ€å¤§å€¼åŠ¨æ€ç¡®å®šã€‚
    åŒæ—¶æ‰“å°å¤šä¸ªå›å½’æŒ‡æ ‡ã€‚

    Args:
        Y_true (array-like): çœŸå®å€¼ (Xè½´)ã€‚
        Y_pred (array-like): é¢„æµ‹å€¼ (Yè½´)ã€‚
        path (str): å›¾ç‰‡ä¿å­˜è·¯å¾„ã€‚
        title (str): å›¾è¡¨æ ‡é¢˜ã€‚
    """

    # 1. ç¡®ä¿æ•°æ®æ˜¯ NumPy æ•°ç»„
    Y_true = np.asarray(Y_true)
    Y_pred = np.asarray(Y_pred)

    # 2. è®¾ç½®å›¾å½¢å°ºå¯¸å’Œé£æ ¼
    plt.figure(figsize=(8, 8))
    plt.style.use('default')

    # 3. åŠ¨æ€è®¡ç®—è½´çš„èŒƒå›´
    global_min = min(Y_true.min(), Y_pred.min())
    global_max = max(Y_true.max(), Y_pred.max())
    padding = (global_max - global_min) * 0.05
    limit_min = global_min - padding
    limit_max = global_max + padding
    plot_range = np.linspace(limit_min, limit_max, 100)

    # 4. ç»˜åˆ¶ y=x åŸºå‡†çº¿
    plt.plot(plot_range, plot_range,
             color='red',
             linestyle='--',
             linewidth=2.5,
             label='$y=x$ (Ideal Prediction)')

    # 5. ç»˜åˆ¶é¢„æµ‹æ•£ç‚¹å›¾
    plt.scatter(Y_true, Y_pred,
                s=20,
                color='#1f77b4',
                alpha=0.7,
                label='Predicted Data')

    # 6. è®¾ç½®åæ ‡è½´èŒƒå›´
    plt.xlim(limit_min, limit_max)
    plt.ylim(limit_min, limit_max)

    # 7. æ·»åŠ æ ‡é¢˜ã€æ ‡ç­¾åŠæ ·å¼
    metrics = calculate_metrics(Y_true, Y_pred)
    metric_text = '\n'.join([f"{k}: {v:.4f}" for k, v in metrics.items()])
    full_title = f"{title}\n{metric_text}"

    plt.title(full_title, fontsize=14, fontweight='bold')
    plt.xlabel('True Values', fontsize=14)
    plt.ylabel('Predicted Values', fontsize=14)
    plt.xticks(fontsize=12)
    plt.yticks(fontsize=12)
    plt.grid(True, linestyle=':', alpha=0.5)
    plt.legend(fontsize=12, loc='upper left', frameon=True, shadow=True)
    plt.tight_layout()
    plt.savefig(path, dpi=300)
    plt.close()

    print(f"åŠ¨æ€èŒƒå›´çš„é¢„æµ‹ vs. çœŸå®å€¼å›¾å·²ä¿å­˜ä¸º {path}")
    print("æ¨¡å‹æ€§èƒ½æŒ‡æ ‡:")
    for key, value in metrics.items():
        print(f"  {key}: {value:.4f}")




